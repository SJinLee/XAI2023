{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1M7dLGvRAY36ENaTgNVB_cR2qQOMy_TiU",
      "authorship_tag": "ABX9TyOaITg8ouNGjrfWP5OFg5bD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SJinLee/XAI2023/blob/main/x1.explainable2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HwKgmdY9GBvJ"
      },
      "outputs": [],
      "source": [
        "!rm -r train valid\n",
        "!unzip drive/MyDrive/xai/car_or_truck.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, warnings\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import gridspec\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory"
      ],
      "metadata": {
        "id": "vRxQLmu2GmjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed=31415):\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "set_seed(31415)"
      ],
      "metadata": {
        "id": "yXSN6rcmGt4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.rc('figure', autolayout=True)\n",
        "plt.rc('axes', labelweight='bold', labelsize='large',\n",
        "       titleweight='bold', titlesize=18, titlepad=10)\n",
        "plt.rc('image', cmap='magma')\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "OpfDW_BzG87H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds_train_ = image_dataset_from_directory(\n",
        "    'train',\n",
        "    labels='inferred',\n",
        "    label_mode='binary',\n",
        "    image_size=[128, 128],\n",
        "    interpolation='nearest',\n",
        "    batch_size=64,\n",
        "    shuffle=True,\n",
        ")\n",
        "ds_valid_ = image_dataset_from_directory(\n",
        "    'valid',\n",
        "    labels='inferred',\n",
        "    label_mode='binary',\n",
        "    image_size=[128, 128],\n",
        "    interpolation='nearest',\n",
        "    batch_size=64,\n",
        "    shuffle=False,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MG_dEhqhHBR_",
        "outputId": "cca8f045-af7d-4009-9fd3-ae947dad401b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5117 files belonging to 2 classes.\n",
            "Found 5051 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Pipeline\n",
        "def convert_to_float(image, label):\n",
        "    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
        "    return image, label\n",
        "\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "ds_train = (\n",
        "    ds_train_\n",
        "    .map(convert_to_float)\n",
        "    .cache()\n",
        "    .prefetch(buffer_size=AUTOTUNE)\n",
        ")\n",
        "ds_valid = (\n",
        "    ds_valid_\n",
        "    .map(convert_to_float)\n",
        "    .cache()\n",
        "    .prefetch(buffer_size=AUTOTUNE)\n",
        ")"
      ],
      "metadata": {
        "id": "6foM_qKYHIb_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf cv-course-models\n",
        "!unzip drive/MyDrive/xai/base_models.zip"
      ],
      "metadata": {
        "id": "FDa9zhF8HpdH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_base = tf.keras.models.load_model(\n",
        "    'cv-course-models/vgg16-pretrained-base',\n",
        ")\n",
        "pretrained_base.trainable = False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GtQUboXfHujQ",
        "outputId": "ff3c1059-69bb-4922-b226-f285ab9f8bb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model = keras.Sequential([\n",
        "    pretrained_base,\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(6, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid'),\n",
        "])"
      ],
      "metadata": {
        "id": "cDnQVpLsH9vv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['binary_accuracy'],\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    ds_train,\n",
        "    validation_data=ds_valid,\n",
        "    epochs=20,\n",
        "    verbose=1,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXS3Rz8JIHTw",
        "outputId": "30b397d0-5a43-4acf-f119-1cb0adbf4da8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "80/80 [==============================] - 20s 175ms/step - loss: 0.5798 - binary_accuracy: 0.7080 - val_loss: 0.5239 - val_binary_accuracy: 0.8214\n",
            "Epoch 2/20\n",
            "80/80 [==============================] - 12s 151ms/step - loss: 0.4959 - binary_accuracy: 0.8054 - val_loss: 0.4802 - val_binary_accuracy: 0.8351\n",
            "Epoch 3/20\n",
            "80/80 [==============================] - 12s 151ms/step - loss: 0.4560 - binary_accuracy: 0.8358 - val_loss: 0.4576 - val_binary_accuracy: 0.8404\n",
            "Epoch 4/20\n",
            "80/80 [==============================] - 16s 208ms/step - loss: 0.4246 - binary_accuracy: 0.8636 - val_loss: 0.4407 - val_binary_accuracy: 0.8472\n",
            "Epoch 5/20\n",
            "80/80 [==============================] - 12s 154ms/step - loss: 0.3983 - binary_accuracy: 0.8806 - val_loss: 0.4312 - val_binary_accuracy: 0.8412\n",
            "Epoch 6/20\n",
            "80/80 [==============================] - 12s 155ms/step - loss: 0.3756 - binary_accuracy: 0.8933 - val_loss: 0.4203 - val_binary_accuracy: 0.8480\n",
            "Epoch 7/20\n",
            "80/80 [==============================] - 12s 157ms/step - loss: 0.3544 - binary_accuracy: 0.9038 - val_loss: 0.4149 - val_binary_accuracy: 0.8478\n",
            "Epoch 8/20\n",
            "80/80 [==============================] - 12s 155ms/step - loss: 0.3365 - binary_accuracy: 0.9138 - val_loss: 0.4100 - val_binary_accuracy: 0.8489\n",
            "Epoch 9/20\n",
            "80/80 [==============================] - 12s 155ms/step - loss: 0.3168 - binary_accuracy: 0.9216 - val_loss: 0.4053 - val_binary_accuracy: 0.8573\n",
            "Epoch 10/20\n",
            "80/80 [==============================] - 12s 155ms/step - loss: 0.3035 - binary_accuracy: 0.9265 - val_loss: 0.3860 - val_binary_accuracy: 0.8672\n",
            "Epoch 11/20\n",
            "80/80 [==============================] - 13s 157ms/step - loss: 0.2933 - binary_accuracy: 0.9255 - val_loss: 0.3863 - val_binary_accuracy: 0.8634\n",
            "Epoch 12/20\n",
            "24/80 [========>.....................] - ETA: 4s - loss: 0.2874 - binary_accuracy: 0.9297"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "history_frame = pd.DataFrame(history.history)\n",
        "history_frame.loc[:, ['loss', 'val_loss']].plot()\n",
        "history_frame.loc[:, ['binary_accuracy', 'val_binary_accuracy']].plot();"
      ],
      "metadata": {
        "id": "aG9YxbtTLIyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import load_img\n",
        "# load the image with the required shape\n",
        "img = load_img('/content/valid/Car/05138.jpeg', target_size=(224, 224))"
      ],
      "metadata": {
        "id": "3GMRj8OEIMGZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import img_to_array\n",
        "from tensorflow import expand_dims\n",
        "# convert the image to an array\n",
        "img = img_to_array(img)\n",
        "# expand dimensions so that it represents a single 'sample'\n",
        "img = expand_dims(img, axis=0)\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "# prepare the image (e.g. scale pixel values for the vgg)\n",
        "img = preprocess_input(img)"
      ],
      "metadata": {
        "id": "U4Yw06UxKscd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_plot = img[0,:,:,::-1].numpy()\n",
        "plt.imshow((img_plot-img_plot.min())/(img_plot.max()-img_plot.min()))"
      ],
      "metadata": {
        "id": "_haH3_RiK29A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img.numpy().max()"
      ],
      "metadata": {
        "id": "4z5UQmDELVMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img.numpy().min()"
      ],
      "metadata": {
        "id": "l5wtEVlRLlOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for a in ds_train:\n",
        "    break"
      ],
      "metadata": {
        "id": "IAong8rELqLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a[0][0].shape"
      ],
      "metadata": {
        "id": "dBq8bBKTMc2b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a[0][0].numpy().max()"
      ],
      "metadata": {
        "id": "yv5IPXE4Mev0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a[0][0].numpy().min()"
      ],
      "metadata": {
        "id": "BSartrQyMnIi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import load_img\n",
        "# load the image with the required shape\n",
        "img = load_img('/content/valid/Car/05138.jpeg', target_size=(128, 128))\n",
        "from keras.utils import img_to_array\n",
        "from tensorflow import expand_dims\n",
        "# convert the image to an array\n",
        "img = img_to_array(img)\n",
        "# expand dimensions so that it represents a single 'sample'\n",
        "img = expand_dims(img, axis=0)\n",
        "img = img / 255"
      ],
      "metadata": {
        "id": "iXmK7ViyMrcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img.numpy().max(),img.numpy().min()"
      ],
      "metadata": {
        "id": "ml0gfK0xNAVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_plot = img[0,:,:,:].numpy()\n",
        "plt.imshow(img_plot)"
      ],
      "metadata": {
        "id": "8Mh1JUqMNBZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(img)"
      ],
      "metadata": {
        "id": "IcmZUeB9NXCD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_numpy = img.numpy()\n",
        "img_numpy[:,80:100,10:30,:] = 0"
      ],
      "metadata": {
        "id": "ArTR6G9VN2oN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(img_numpy[0,:,:,:])"
      ],
      "metadata": {
        "id": "mqE9J4FKOUKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(img_numpy)"
      ],
      "metadata": {
        "id": "pyF4U_InOrC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import load_img\n",
        "# load the image with the required shape\n",
        "img = load_img('/content/valid/Car/05138.jpeg', target_size=(128, 128))\n",
        "from keras.utils import img_to_array\n",
        "from tensorflow import expand_dims\n",
        "# convert the image to an array\n",
        "img = img_to_array(img)\n",
        "# expand dimensions so that it represents a single 'sample'\n",
        "img = expand_dims(img, axis=0)\n",
        "img = img / 255\n",
        "\n",
        "img_numpy = img.numpy()\n",
        "img_numpy[:,70:110,10:120,:] = 0\n",
        "\n",
        "plt.imshow(img_numpy[0,:,:,:])\n",
        "\n",
        "model.predict(img_numpy)"
      ],
      "metadata": {
        "id": "7BQbCSztO2mj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import load_img\n",
        "# load the image with the required shape\n",
        "img = load_img('/content/valid/Truck/05157.jpeg', target_size=(128, 128))\n",
        "from keras.utils import img_to_array\n",
        "from tensorflow import expand_dims\n",
        "# convert the image to an array\n",
        "img = img_to_array(img)\n",
        "# expand dimensions so that it represents a single 'sample'\n",
        "img = expand_dims(img, axis=0)\n",
        "img = img / 255\n",
        "\n",
        "img_numpy = img.numpy()\n",
        "# img_numpy[:,70:110,10:120,:] = 0\n",
        "\n",
        "plt.imshow(img_numpy[0,:,:,:])\n",
        "\n",
        "model.predict(img_numpy)"
      ],
      "metadata": {
        "id": "LZj-LG-2PJGM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ouTcjS-lPycc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}